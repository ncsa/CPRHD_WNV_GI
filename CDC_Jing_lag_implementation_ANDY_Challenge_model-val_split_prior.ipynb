{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1592405045546,
     "user": {
      "displayName": "Andy Sima",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPi40RA26EYAcTjgnQiTI1GaZjpqHDI9zRAq2X3jE=s64",
      "userId": "10714226330436444093"
     },
     "user_tz": 300
    },
    "id": "d3XU1S86Dem8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import itertools  \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, TomekLinks, EditedNearestNeighbours, NearMiss, RandomUnderSampler\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1592405049039,
     "user": {
      "displayName": "Andy Sima",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPi40RA26EYAcTjgnQiTI1GaZjpqHDI9zRAq2X3jE=s64",
      "userId": "10714226330436444093"
     },
     "user_tz": 300
    },
    "id": "c4XHzkWuDenN"
   },
   "outputs": [],
   "source": [
    "#Function to print confusion matrix in a nice format.\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vm5lg4uEDenY",
    "outputId": "528eb027-2a0c-4557-f899-d856bd1ea589"
   },
   "outputs": [],
   "source": [
    "#Importing training and testing data\n",
    "train_path=\"C:/Users/andre/NCSA_Python/SPIN_CDC/jing_data_values.csv\"\n",
    "temporal_df=pd.read_csv(train_path)\n",
    "test_path=\"C:/Users/andre/NCSA_Python/SPIN_CDC/jing_test_values.csv\"\n",
    "temporal_df_test=pd.read_csv(test_path)\n",
    "\n",
    "#Importing county names\n",
    "county_path=\"C:/Users/andre/NCSA_Python/SPIN_CDC/County_name.csv\"  #CAN USE JING_DATA_KEYS?\n",
    "df_county=pd.read_csv(county_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1592405082918,
     "user": {
      "displayName": "Andy Sima",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPi40RA26EYAcTjgnQiTI1GaZjpqHDI9zRAq2X3jE=s64",
      "userId": "10714226330436444093"
     },
     "user_tz": 300
    },
    "id": "6Tew4TY5DenS"
   },
   "outputs": [],
   "source": [
    "##Specifying training data parameters.\n",
    "years=range(2000,2019)\n",
    "num_years=1 #Unnecessary for Jing's Data structure, though hers lags by five years, initial skip one (i.e. 2018's lags are 2016-2012)\n",
    "\n",
    "#Features/columns that will be used for prediction.\n",
    "feat=list(temporal_df)\n",
    "features=feat[1:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwxQaUA5Denf",
    "outputId": "a1d217c5-74fa-4a99-cf4d-3c5b33f69936"
   },
   "outputs": [],
   "source": [
    "del temporal_df['Unnamed: 0']\n",
    "del temporal_df_test['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_lag1</th>\n",
       "      <th>count_lag2</th>\n",
       "      <th>count_lag3</th>\n",
       "      <th>count_lag4</th>\n",
       "      <th>count_lag5</th>\n",
       "      <th>stateAvg_lag1</th>\n",
       "      <th>Incident_nominal_lag1</th>\n",
       "      <th>neigh_death_count_lag1</th>\n",
       "      <th>temp_lag1</th>\n",
       "      <th>prec_lag1</th>\n",
       "      <th>hum_lag1</th>\n",
       "      <th>gini_lag1</th>\n",
       "      <th>County_type_lag1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>291.911606</td>\n",
       "      <td>3.166458</td>\n",
       "      <td>75.178524</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>291.539614</td>\n",
       "      <td>3.900827</td>\n",
       "      <td>75.858843</td>\n",
       "      <td>0.501472</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>292.317544</td>\n",
       "      <td>3.087140</td>\n",
       "      <td>71.706429</td>\n",
       "      <td>0.536239</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>293.287243</td>\n",
       "      <td>2.213271</td>\n",
       "      <td>67.009978</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>291.567389</td>\n",
       "      <td>3.681567</td>\n",
       "      <td>72.971491</td>\n",
       "      <td>0.477927</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>292.257058</td>\n",
       "      <td>3.256280</td>\n",
       "      <td>75.457933</td>\n",
       "      <td>0.536441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>292.009713</td>\n",
       "      <td>3.761215</td>\n",
       "      <td>75.922392</td>\n",
       "      <td>0.511025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>292.840826</td>\n",
       "      <td>2.690377</td>\n",
       "      <td>71.624671</td>\n",
       "      <td>0.546820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>293.433240</td>\n",
       "      <td>2.674722</td>\n",
       "      <td>68.627887</td>\n",
       "      <td>0.543446</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>291.893988</td>\n",
       "      <td>3.646083</td>\n",
       "      <td>74.086555</td>\n",
       "      <td>0.492225</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     count_lag1  count_lag2  count_lag3  count_lag4  count_lag5  \\\n",
       "0             0           0           1           0           0   \n",
       "1             0           0           0           1           0   \n",
       "2             0           0           0           0           1   \n",
       "3             0           0           0           0           0   \n",
       "4             0           0           0           0           0   \n",
       "..          ...         ...         ...         ...         ...   \n",
       "650           0           2           7           0           0   \n",
       "651           5           0           2           7           0   \n",
       "652           0           5           0           2           7   \n",
       "653          11           0           5           0           2   \n",
       "654           0          11           0           5           0   \n",
       "\n",
       "     stateAvg_lag1  Incident_nominal_lag1  neigh_death_count_lag1   temp_lag1  \\\n",
       "0         0.223881                      1                       0  291.911606   \n",
       "1         0.089552                      1                       6  291.539614   \n",
       "2         0.119403                      1                       0  292.317544   \n",
       "3         0.253731                      1                      11  293.287243   \n",
       "4         0.164179                      1                       0  291.567389   \n",
       "..             ...                    ...                     ...         ...   \n",
       "650       0.223881                      1                       0  292.257058   \n",
       "651       0.089552                      1                       1  292.009713   \n",
       "652       0.119403                      1                       0  292.840826   \n",
       "653       0.253731                      1                       0  293.433240   \n",
       "654       0.164179                      1                       0  291.893988   \n",
       "\n",
       "     prec_lag1   hum_lag1  gini_lag1  County_type_lag1  1  2  3  4  5  6  7  \\\n",
       "0     3.166458  75.178524   0.519989                 1  1  0  0  0  0  0  0   \n",
       "1     3.900827  75.858843   0.501472                 1  1  0  0  0  0  0  0   \n",
       "2     3.087140  71.706429   0.536239                 1  1  0  0  0  0  0  0   \n",
       "3     2.213271  67.009978   0.524172                 1  1  0  0  0  0  0  0   \n",
       "4     3.681567  72.971491   0.477927                 1  1  0  0  0  0  0  0   \n",
       "..         ...        ...        ...               ... .. .. .. .. .. .. ..   \n",
       "650   3.256280  75.457933   0.536441                 1  1  0  0  0  0  0  0   \n",
       "651   3.761215  75.922392   0.511025                 1  0  0  0  1  0  0  0   \n",
       "652   2.690377  71.624671   0.546820                 1  1  0  0  0  0  0  0   \n",
       "653   2.674722  68.627887   0.543446                 1  1  0  0  0  0  0  0   \n",
       "654   3.646083  74.086555   0.492225                 1  1  0  0  0  0  0  0   \n",
       "\n",
       "     8  9  10  11  12  13  14  15  \n",
       "0    0  0   0   0   0   0   0   0  \n",
       "1    0  0   0   0   0   0   0   0  \n",
       "2    0  0   0   0   0   0   0   0  \n",
       "3    0  0   0   0   0   0   0   0  \n",
       "4    0  0   0   0   0   0   0   0  \n",
       "..  .. ..  ..  ..  ..  ..  ..  ..  \n",
       "650  0  0   0   0   0   0   0   0  \n",
       "651  0  0   0   0   0   0   0   0  \n",
       "652  0  0   0   0   0   0   0   0  \n",
       "653  0  0   0   0   0   0   0   0  \n",
       "654  0  0   0   0   0   0   0   0  \n",
       "\n",
       "[655 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_df.head(655)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31Df5ABIDenj",
    "outputId": "3ceed99c-7080-4da5-9e2e-456165674be4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 7042,\n",
       " 2: 664,\n",
       " 3: 312,\n",
       " 4: 88,\n",
       " 5: 39,\n",
       " 6: 28,\n",
       " 7: 13,\n",
       " 8: 8,\n",
       " 9: 5,\n",
       " 10: 5,\n",
       " 11: 5,\n",
       " 12: 15,\n",
       " 13: 7,\n",
       " 14: 3,\n",
       " 15: 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking frequency of instances for each class\n",
    "dict_freq={}\n",
    "for i in range(1,16):\n",
    "    dict_freq[i]=len(temporal_df[temporal_df[str(i)]==1])\n",
    "dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the dictionary for different oversampling values, seems to be supported for all oversampling?\n",
    "#Doesn't matter anyway, not useful\n",
    "over_dict_list=[]\n",
    "over_dict={}\n",
    "for j in dict_freq.values():\n",
    "    if j > 10000:\n",
    "        over_dict_list.append(j)\n",
    "    elif j > 1000:\n",
    "        over_dict_list.append(j)\n",
    "    elif j > 100:\n",
    "        over_dict_list.append(j*3)\n",
    "    elif j > 50:\n",
    "        over_dict_list.append(j*7)\n",
    "    elif j > 10:\n",
    "        over_dict_list.append(j*15)\n",
    "    elif j > 1:\n",
    "        over_dict_list.append(j*15)\n",
    "\n",
    "for i in range(1,16):\n",
    "    over_dict[i]=over_dict_list[i-1]   \n",
    "\n",
    "#dictionaries are only supported for random undersampling\n",
    "under_dict_list=[]\n",
    "under_dict={}\n",
    "for j in dict_freq.values():\n",
    "    if j > 10000:\n",
    "        under_dict_list.append(int(j/5))\n",
    "    elif j > 1000:\n",
    "        under_dict_list.append(int(j/7))\n",
    "    elif j > 100:\n",
    "        under_dict_list.append(j)\n",
    "    elif j > 10:\n",
    "        under_dict_list.append(j)\n",
    "    elif j > 1:\n",
    "        under_dict_list.append(j)\n",
    "\n",
    "for i in range(1,16):\n",
    "    under_dict[i]=under_dict_list[i-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combination oversampling and undersampling\n",
    "combined_dict=over_dict.copy()\n",
    "combined_dict[1]=7500\n",
    "combined_dict[2]=1000\n",
    "#combined_dict\n",
    "#over_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A means to oversample the data - imblearn iteration\n",
    "\n",
    "#THIS IS INITIALLY TURNED OFF FOR JING'S DATA\n",
    "#TO TURN IT ON, uncomment lines 17, 18, 22, 23, and swap comment from line 3 to line 2 in next box.\n",
    "\n",
    "#Classification of samples\n",
    "temporal_df_classify = temporal_df.iloc[:,13:28]\n",
    "temporal_df_values = temporal_df.iloc[:,0:13]\n",
    "classify_array=[]\n",
    "for j in range(0,40391):\n",
    "    for i in range (0,15):\n",
    "        if temporal_df_classify.iloc[j,i]==1:\n",
    "            classify_array.append(i+1)\n",
    "\n",
    "            \n",
    "#over_dict for oversampling, under_dict for undersampling, combined_dict for both; swap out in undersampling option\n",
    "#standard oversampling option\n",
    "#ros=RandomOverSampler(sampling_strategy=over_dict) #random oversample using uneven sample sizes, for standard replace \"over_dict\" with \"auto\"\n",
    "#oversampled_temporal_df,oversampled_classified_df=ros.fit_resample(temporal_df,classify_array)  #random oversample\n",
    "\n",
    "#standard undersampling option\n",
    "#be sure to adjust dictionary and variable names\n",
    "undertale = RandomUnderSampler(sampling_strategy=under_dict) #undersampling with random undersample\n",
    "oversampled_temporal_df,oversampled_classified_df=undertale.fit_resample(temporal_df,classify_array)\n",
    "\n",
    "#oversampled_temporal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1lKW7OdDeno"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_lag1</th>\n",
       "      <th>count_lag2</th>\n",
       "      <th>count_lag3</th>\n",
       "      <th>count_lag4</th>\n",
       "      <th>count_lag5</th>\n",
       "      <th>stateAvg_lag1</th>\n",
       "      <th>Incident_nominal_lag1</th>\n",
       "      <th>neigh_death_count_lag1</th>\n",
       "      <th>temp_lag1</th>\n",
       "      <th>prec_lag1</th>\n",
       "      <th>hum_lag1</th>\n",
       "      <th>gini_lag1</th>\n",
       "      <th>County_type_lag1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>288.961886</td>\n",
       "      <td>3.671998</td>\n",
       "      <td>76.047545</td>\n",
       "      <td>0.497831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>289.398978</td>\n",
       "      <td>2.334227</td>\n",
       "      <td>69.896953</td>\n",
       "      <td>0.555036</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5770</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.256098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>291.207690</td>\n",
       "      <td>3.410320</td>\n",
       "      <td>72.703274</td>\n",
       "      <td>0.486447</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294.202029</td>\n",
       "      <td>2.462670</td>\n",
       "      <td>70.964268</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>299.028004</td>\n",
       "      <td>1.664599</td>\n",
       "      <td>70.950889</td>\n",
       "      <td>0.645013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7286</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>288.262733</td>\n",
       "      <td>2.755042</td>\n",
       "      <td>73.824714</td>\n",
       "      <td>0.546467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>287.522367</td>\n",
       "      <td>2.885708</td>\n",
       "      <td>72.963761</td>\n",
       "      <td>0.541945</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>281.710412</td>\n",
       "      <td>1.626275</td>\n",
       "      <td>66.581431</td>\n",
       "      <td>0.413970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>283.748164</td>\n",
       "      <td>2.568934</td>\n",
       "      <td>72.133511</td>\n",
       "      <td>0.613753</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>286.390245</td>\n",
       "      <td>2.982224</td>\n",
       "      <td>74.508088</td>\n",
       "      <td>0.488953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8236 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count_lag1  count_lag2  count_lag3  count_lag4  count_lag5  \\\n",
       "7566           0           0           0           0           0   \n",
       "1423           0           0           0           0           0   \n",
       "5770           0           0           0           0           0   \n",
       "999            0           0           0           0           0   \n",
       "5732           0           0           0           0           0   \n",
       "...          ...         ...         ...         ...         ...   \n",
       "7286           1           6           0           3           1   \n",
       "3046           0           0           0           0           0   \n",
       "4079           0           0           0           0           0   \n",
       "2254           0           0           0           0           0   \n",
       "2915           0           0           0           0           0   \n",
       "\n",
       "      stateAvg_lag1  Incident_nominal_lag1  neigh_death_count_lag1  \\\n",
       "7566       0.052632                      1                       2   \n",
       "1423       0.173333                      0                       0   \n",
       "5770       1.256098                      0                       0   \n",
       "999        0.088050                      0                       0   \n",
       "5732       0.444882                      0                       2   \n",
       "...             ...                    ...                     ...   \n",
       "7286       0.960784                      1                       5   \n",
       "3046       0.530435                      0                       3   \n",
       "4079       0.025641                      0                       0   \n",
       "2254       0.225806                      1                       1   \n",
       "2915       0.025000                      0                       0   \n",
       "\n",
       "       temp_lag1  prec_lag1   hum_lag1  gini_lag1  County_type_lag1  1  2  3  \\\n",
       "7566  288.961886   3.671998  76.047545   0.497831                 1  0  1  0   \n",
       "1423  289.398978   2.334227  69.896953   0.555036                 0  1  0  0   \n",
       "5770  291.207690   3.410320  72.703274   0.486447                 0  1  0  0   \n",
       "999   294.202029   2.462670  70.964268   0.467299                 0  1  0  0   \n",
       "5732  299.028004   1.664599  70.950889   0.645013                 0  1  0  0   \n",
       "...          ...        ...        ...        ...               ... .. .. ..   \n",
       "7286  288.262733   2.755042  73.824714   0.546467                 1  0  1  0   \n",
       "3046  287.522367   2.885708  72.963761   0.541945                 0  1  0  0   \n",
       "4079  281.710412   1.626275  66.581431   0.413970                 0  1  0  0   \n",
       "2254  283.748164   2.568934  72.133511   0.613753                 0  1  0  0   \n",
       "2915  286.390245   2.982224  74.508088   0.488953                 0  1  0  0   \n",
       "\n",
       "      4  5  6  7  8  9  10  11  12  13  14  15  \n",
       "7566  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "1423  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "5770  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "999   0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "5732  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "...  .. .. .. .. .. ..  ..  ..  ..  ..  ..  ..  \n",
       "7286  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "3046  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "4079  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "2254  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "2915  0  0  0  0  0  0   0   0   0   0   0   0  \n",
       "\n",
       "[8236 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using unbalanced data\n",
    "#temporal_df = temporal_df.sample(frac = 1,random_state=5) #Shuffling the data - Standard, not oversampled\n",
    "temporal_df = oversampled_temporal_df.sample(frac = 1,random_state=5) #Shuffling the data - oversampled, imblearn\n",
    "X_pre = temporal_df.iloc[:, 0:(len(features))]\n",
    "Y_pre = temporal_df.iloc[:, (len(features)):]\n",
    "X=X_pre.values\n",
    "Y=Y_pre.values\n",
    "temporal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gQjlQhkDenv",
    "outputId": "c4bc0b34-c4a8-44d5-b8a4-5289ba29a5a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7042,  664,  312,   88,   39,   28,   13,    8,    5,    5,    5,\n",
       "         15,    7,    3,    2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows all the class labels are now equally represented\n",
    "#Successfully Oversampled\n",
    "y=np.argmax(Y, axis=1)\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VabCVE9bDen2"
   },
   "source": [
    "## LSTM Implementation for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gU1TLrAJDen2"
   },
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0vruIGJDen3"
   },
   "outputs": [],
   "source": [
    "def create_network_hyp(nodes_1,lstm_node,dropout,recurrent_dropout):\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization(input_shape=(num_years, len(features))))\n",
    "    network.add(Dense(nodes_1, activation=\"tanh\"))\n",
    "    network.add(LSTM(lstm_node, dropout = dropout, recurrent_dropout = recurrent_dropout, activation=\"tanh\"))\n",
    "    network.add(Dense(15, activation=\"softmax\"))\n",
    "    network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8jhuUjYDen6"
   },
   "outputs": [],
   "source": [
    "#Objective function to be minimized\n",
    "def objective(params):\n",
    "    nodes_1=params[\"nodes_1\"]\n",
    "    dropout=params[\"dropout\"]\n",
    "    recurrent_dropout=params[\"recurrent_dropout\"]\n",
    "    lstm_node=params[\"lstm_node\"]\n",
    "    \n",
    "    indices=[i for i in range(len(X))]\n",
    "    indices=shuffle(indices, random_state=4)\n",
    "    split_ratio=0.8    #80-20 split ratio for train-val set\n",
    "    train_index=indices[0:int(split_ratio*len(X))]\n",
    "    val_index=indices[int(split_ratio*len(X)):]\n",
    "\n",
    "    \n",
    "    X_pre_train = temporal_df.iloc[train_index, 0:(num_years*len(features))]\n",
    "    Y_pre_train = temporal_df.iloc[train_index, (num_years*len(features)):]\n",
    "    X_pre_val = temporal_df.iloc[val_index, 0:(num_years*len(features))]\n",
    "    Y_pre_val = temporal_df.iloc[val_index, (num_years*len(features)):]\n",
    "    X_pre_train_combine=pd.concat([X_pre_train, Y_pre_train], axis=1)\n",
    "    \n",
    "    #Oversampling the training data to balance the classes\n",
    "    num_cl=len(X_pre_train_combine[X_pre_train_combine[\"1\"]==1])\n",
    "    df_balanced=X_pre_train_combine[X_pre_train_combine[\"1\"]==1]\n",
    "    df_balanced_train = df_balanced.sample(frac = 1, random_state=4)   #Shuffling the data\n",
    "    X_pre_train = df_balanced_train.iloc[:, 0:(num_years*len(features))]\n",
    "    Y_pre_train = df_balanced_train.iloc[:, (num_years*len(features)):]\n",
    "    \n",
    "    \n",
    "    X_train=X_pre_train.values\n",
    "    Y_train=Y_pre_train.values\n",
    "    X_val=X_pre_val.values\n",
    "    Y_val=Y_pre_val.values\n",
    "    \n",
    "    #Transforming input variables into LSTM input format\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_years, len(features))\n",
    "    X_val = X_val.reshape(X_val.shape[0], num_years, len(features))\n",
    "    Y_train=Y_train\n",
    "    Y_val=Y_val\n",
    "    \n",
    "    #Creating model\n",
    "    model=create_network_hyp(nodes_1,lstm_node,dropout,recurrent_dropout)\n",
    "    Hist=model.fit(X_train, Y_train, epochs=1, validation_data=(X_val, Y_val), verbose=2, class_weight=None)\n",
    "    \n",
    "    #Final epoch accuracies for validation dataset\n",
    "    acc_val=Hist.history[\"val_accuracy\"][-1]\n",
    "\n",
    "    return -acc_val   #Minimizing the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KvNkS3wrDen9"
   },
   "outputs": [],
   "source": [
    "#Declaring hyperparameter search space\n",
    "space={\"nodes_1\": hp.choice(\"nodes_1\", range(4,20)), \"dropout\": hp.uniform(\"dropout\", 0.1, 0.4),\"lstm_node\":hp.choice(\"lstm_node\", range(15,20)), \"recurrent_dropout\": hp.uniform(\"recurrent_dropout\", 0.1, 0.4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLgLrUosDeoA"
   },
   "outputs": [],
   "source": [
    "# Create a trials object\n",
    "tpe_trials = Trials()\n",
    "# Create the algorithm\n",
    "tpe_algo = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owW7SLIiDeoF",
    "outputId": "fc767c62-ca57-4530-9cc2-f38d192b5cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5626 samples, validate on 1648 samples       \n",
      "Epoch 1/1                                             \n",
      " - 1s - loss: 1.8340 - accuracy: 0.7744 - val_loss: 1.6886 - val_accuracy: 0.6905\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.8023 - accuracy: 0.7353 - val_loss: 1.8652 - val_accuracy: 0.7791\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.7480 - accuracy: 0.7426 - val_loss: 0.8593 - val_accuracy: 0.8234\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.7463 - accuracy: 0.7057 - val_loss: 1.1847 - val_accuracy: 0.7992\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.9266 - accuracy: 0.7885 - val_loss: 0.7963 - val_accuracy: 0.8356\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.6468 - accuracy: 0.7826 - val_loss: 0.6728 - val_accuracy: 0.8598\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.9767 - accuracy: 0.7849 - val_loss: 0.7896 - val_accuracy: 0.8525\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.7378 - accuracy: 0.7720 - val_loss: 1.3153 - val_accuracy: 0.7943\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.6212 - accuracy: 0.7855 - val_loss: 1.1201 - val_accuracy: 0.8380\n",
      "\n",
      "Train on 5626 samples, validate on 1648 samples                                  \n",
      "Epoch 1/1                                                                        \n",
      " - 1s - loss: 1.9560 - accuracy: 0.8640 - val_loss: 1.9730 - val_accuracy: 0.8556\n",
      "\n",
      "100%|██████████| 10/10 [00:20<00:00,  2.02s/trial, best loss: -0.8598300814628601]\n"
     ]
    }
   ],
   "source": [
    "# Run bayesian optimization for hyperparameter tuning\n",
    "tpe_best = fmin(fn=objective, space=space, algo=tpe_algo, trials=tpe_trials, max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25BXejW2DeoJ",
    "outputId": "0a0bd0b8-540f-4f45-be56-0d161951ba29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>iteration</th>\n",
       "      <th>nodes_1</th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.859830</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.165592</td>\n",
       "      <td>0.218773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.852549</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.147146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794296</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.240405</td>\n",
       "      <td>0.151064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.837985</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.148132</td>\n",
       "      <td>0.332574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.855583</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.147838</td>\n",
       "      <td>0.221459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  iteration  nodes_1   dropout  recurrent_dropout\n",
       "5  0.859830          5       15  0.165592           0.218773\n",
       "6  0.852549          6        2  0.327778           0.147146\n",
       "7  0.794296          7        7  0.240405           0.151064\n",
       "8  0.837985          8       13  0.148132           0.332574\n",
       "9  0.855583          9        2  0.147838           0.221459"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpe_results = pd.DataFrame({'Accuracy': [-x['loss'] for x in tpe_trials.results], \n",
    "                            'iteration': tpe_trials.idxs_vals[0]['nodes_1'],\n",
    "                            'nodes_1': tpe_trials.idxs_vals[1]['nodes_1'],\n",
    "                            'dropout': tpe_trials.idxs_vals[1]['dropout'],\n",
    "                            'recurrent_dropout': tpe_trials.idxs_vals[1]['recurrent_dropout']})\n",
    "                            \n",
    "tpe_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeLXbMUfDeoQ",
    "outputId": "279835a3-2436-4b28-d3fc-6c2aac53ca68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.16559244595976896, 'lstm_node': 1, 'nodes_1': 15, 'recurrent_dropout': 0.21877256453658203}\n"
     ]
    }
   ],
   "source": [
    "#Best parameters\n",
    "print(tpe_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhqPl30tDeoa"
   },
   "source": [
    "Training of model after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HK5WZ1g4Deoa"
   },
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization(input_shape=(num_years, len(features))))\n",
    "    network.add(Dense(4, activation=\"tanh\"))\n",
    "    network.add(LSTM(14, dropout = 0.2, recurrent_dropout = 0.2, activation=\"tanh\"))\n",
    "    network.add(Dense(15, activation=\"softmax\"))\n",
    "    network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43QhMEr4Deod",
    "outputId": "89c15229-3116-4198-c745-f83a3451a85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4710 samples, validate on 2746 samples\n",
      "Epoch 1/15\n",
      " - 1s - loss: 2.1632 - accuracy: 0.7486 - val_loss: 1.7242 - val_accuracy: 0.7640\n",
      "Epoch 2/15\n",
      " - 0s - loss: 0.6013 - accuracy: 0.9293 - val_loss: 0.7376 - val_accuracy: 0.8412\n",
      "Epoch 3/15\n",
      " - 0s - loss: 0.2112 - accuracy: 0.9953 - val_loss: 0.7807 - val_accuracy: 0.8492\n",
      "Epoch 4/15\n",
      " - 0s - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.8842 - val_accuracy: 0.8492\n",
      "Epoch 5/15\n",
      " - 0s - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.8492\n",
      "Epoch 6/15\n",
      " - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.0722 - val_accuracy: 0.8492\n",
      "Epoch 7/15\n",
      " - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.1266 - val_accuracy: 0.8492\n",
      "Epoch 8/15\n",
      " - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1708 - val_accuracy: 0.8492\n",
      "Epoch 9/15\n",
      " - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2189 - val_accuracy: 0.8492\n",
      "Epoch 10/15\n",
      " - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2622 - val_accuracy: 0.8492\n",
      "Epoch 11/15\n",
      " - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3011 - val_accuracy: 0.8492\n",
      "Epoch 12/15\n",
      " - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3219 - val_accuracy: 0.8492\n",
      "Epoch 13/15\n",
      " - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3703 - val_accuracy: 0.8492\n",
      "Epoch 14/15\n",
      " - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3995 - val_accuracy: 0.8492\n",
      "Epoch 15/15\n",
      " - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.8492\n",
      "Train on 4687 samples, validate on 2745 samples\n",
      "Epoch 1/15\n",
      " - 1s - loss: 2.2590 - accuracy: 0.7666 - val_loss: 2.5147 - val_accuracy: 0.6499\n",
      "Epoch 2/15\n",
      " - 0s - loss: 0.5744 - accuracy: 0.9629 - val_loss: 0.7870 - val_accuracy: 0.8521\n",
      "Epoch 3/15\n",
      " - 0s - loss: 0.1155 - accuracy: 0.9962 - val_loss: 0.9165 - val_accuracy: 0.8576\n",
      "Epoch 4/15\n",
      " - 0s - loss: 0.0403 - accuracy: 0.9989 - val_loss: 1.0343 - val_accuracy: 0.8576\n",
      "Epoch 5/15\n",
      " - 0s - loss: 0.0194 - accuracy: 0.9996 - val_loss: 1.1247 - val_accuracy: 0.8576\n",
      "Epoch 6/15\n",
      " - 0s - loss: 0.0124 - accuracy: 0.9998 - val_loss: 1.1849 - val_accuracy: 0.8576\n",
      "Epoch 7/15\n",
      " - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.2414 - val_accuracy: 0.8576\n",
      "Epoch 8/15\n",
      " - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2855 - val_accuracy: 0.8579\n",
      "Epoch 9/15\n",
      " - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.8576\n",
      "Epoch 10/15\n",
      " - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3600 - val_accuracy: 0.8576\n",
      "Epoch 11/15\n",
      " - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3959 - val_accuracy: 0.8576\n",
      "Epoch 12/15\n",
      " - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4315 - val_accuracy: 0.8576\n",
      "Epoch 13/15\n",
      " - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4611 - val_accuracy: 0.8576\n",
      "Epoch 14/15\n",
      " - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4851 - val_accuracy: 0.8576\n",
      "Epoch 15/15\n",
      " - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5075 - val_accuracy: 0.8576\n",
      "Train on 4687 samples, validate on 2745 samples\n",
      "Epoch 1/15\n",
      " - 1s - loss: 2.2145 - accuracy: 0.7738 - val_loss: 2.6840 - val_accuracy: 0.0958\n",
      "Epoch 2/15\n",
      " - 0s - loss: 0.6070 - accuracy: 0.9689 - val_loss: 0.7462 - val_accuracy: 0.8550\n",
      "Epoch 3/15\n",
      " - 0s - loss: 0.1241 - accuracy: 0.9983 - val_loss: 0.8561 - val_accuracy: 0.8579\n",
      "Epoch 4/15\n",
      " - 0s - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.8579\n",
      "Epoch 5/15\n",
      " - 0s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.0744 - val_accuracy: 0.8579\n",
      "Epoch 6/15\n",
      " - 0s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1542 - val_accuracy: 0.8579\n",
      "Epoch 7/15\n",
      " - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2203 - val_accuracy: 0.8579\n",
      "Epoch 8/15\n",
      " - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2734 - val_accuracy: 0.8579\n",
      "Epoch 9/15\n",
      " - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.3180 - val_accuracy: 0.8579\n",
      "Epoch 10/15\n",
      " - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.8579\n",
      "Epoch 11/15\n",
      " - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4024 - val_accuracy: 0.8579\n",
      "Epoch 12/15\n",
      " - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.4389 - val_accuracy: 0.8579\n",
      "Epoch 13/15\n",
      " - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4647 - val_accuracy: 0.8579\n",
      "Epoch 14/15\n",
      " - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.8579\n",
      "Epoch 15/15\n",
      " - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5313 - val_accuracy: 0.8579\n",
      "Training accuracy:1.0\n",
      "Validation accuracy:0.8549059828122457\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation setup\n",
    "acc_train=[]\n",
    "acc_val=[]\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for train_index, val_index in kf.split(X):   \n",
    "    X_pre_train = temporal_df.iloc[train_index, 0:(num_years*len(features))]\n",
    "    Y_pre_train = temporal_df.iloc[train_index, (num_years*len(features)):]\n",
    "    X_pre_val = temporal_df.iloc[val_index, 0:(num_years*len(features))]\n",
    "    Y_pre_val = temporal_df.iloc[val_index, (num_years*len(features)):]\n",
    "    X_pre_train_combine=pd.concat([X_pre_train, Y_pre_train], axis=1)\n",
    "    \n",
    "    #Oversampling the training data to balance the classes\n",
    "    num_cl=len(X_pre_train_combine[X_pre_train_combine[\"1\"]==1])\n",
    "    df_balanced=X_pre_train_combine[X_pre_train_combine[\"1\"]==1]\n",
    "    df_balanced_train = df_balanced.sample(frac = 1, random_state=4)   #Shuffling the data\n",
    "    X_pre_train = df_balanced_train.iloc[:, 0:(num_years*len(features))]\n",
    "    Y_pre_train = df_balanced_train.iloc[:, (num_years*len(features)):]\n",
    "    #ros=RandomOverSampler(sampling_strategy=\"auto\")\n",
    "    #y=np.array(temporal_df.columns)\n",
    "    #test_temporal_df=ros.fit_resample(temporal_df,y)\n",
    "    \n",
    "    \n",
    "    X_train=X_pre_train.values\n",
    "    Y_train=Y_pre_train.values\n",
    "    X_val=X_pre_val.values\n",
    "    Y_val=Y_pre_val.values\n",
    "    \n",
    "    #Transforming input variables into LSTM input format\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_years, len(features))\n",
    "    X_val = X_val.reshape(X_val.shape[0], num_years, len(features))\n",
    "    Y_train=Y_train\n",
    "    Y_val=Y_val\n",
    "    \n",
    "    #Creating model\n",
    "    model=create_network()\n",
    "    Hist=model.fit(X_train, Y_train, epochs=15, validation_data=(X_val, Y_val), verbose=2, class_weight=None)\n",
    "    \n",
    "    #Final epoch accuracies for training and validation dataset\n",
    "    acc_train.append(Hist.history[\"accuracy\"][-1])\n",
    "    acc_val.append(Hist.history[\"val_accuracy\"][-1])\n",
    "    \n",
    "print(\"Training accuracy:\" + str(np.mean(acc_train)))\n",
    "print(\"Validation accuracy:\" + str(np.mean(acc_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJSiuBXxDeog",
    "outputId": "446f0cb2-443f-4a89-f832-8774e3ff63cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(Hist.history['accuracy'])\n",
    "plt.plot(Hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(Hist.history['loss'])\n",
    "plt.plot(Hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ojT1-BIDeom"
   },
   "outputs": [],
   "source": [
    "X_test=temporal_df_test.values\n",
    "X_test = X_test.reshape(X_test.shape[0], num_years, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VFD7qhq1Deop"
   },
   "outputs": [],
   "source": [
    "#Predicting value for train, val, and test datasets\n",
    "pred_train=model.predict(X_train)\n",
    "pred_val=model.predict(X_val)\n",
    "pred_test=model.predict(X_test)\n",
    "#pred_all=model.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uw1-KdOFDeox"
   },
   "outputs": [],
   "source": [
    "#Converting probabilities to class labels\n",
    "pred_train_class=np.argmax(pred_train, axis=1)+1\n",
    "pred_train_class=list(map(lambda x: str(x), pred_train_class))\n",
    "pred_val_class=np.argmax(pred_val, axis=1)+1\n",
    "pred_val_class=list(map(lambda x: str(x), pred_val_class))\n",
    "pred_test_class=np.argmax(pred_test, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VX3YaPluDeo2"
   },
   "outputs": [],
   "source": [
    "true_train_class=np.argmax(Y_train, axis=1)+1\n",
    "true_train_class=list(map(lambda x: str(x), true_train_class))\n",
    "true_val_class=np.argmax(Y_val, axis=1)+1\n",
    "true_val_class=list(map(lambda x: str(x), true_val_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7A7M9ACWDeo6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass labels=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "labels = [str(i) for i in range(1,16)]\n",
    "cm_train = confusion_matrix(true_train_class, pred_train_class , labels)\n",
    "cm_val = confusion_matrix(true_val_class, pred_val_class , labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cEF31k-Deo-",
    "outputId": "9ae82c8d-c3fb-495b-9889-815d5de6a716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1     2     3     4     5     6     7     8     9    10    11    12    13    14    15 \n",
      "        1 4687.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        6   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        7   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        8   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        9   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       10   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       11   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       12   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       13   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       14   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       15   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(cm_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqtJvB8bDepB",
    "outputId": "a5d92e1b-12a3-4fb1-d0f6-472453ec8240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1     2     3     4     5     6     7     8     9    10    11    12    13    14    15 \n",
      "        1 2355.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        2 240.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        3  84.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        4  27.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        5   6.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        6  12.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        7   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        8   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        9   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       10   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       11   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       12   7.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       13   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       14   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       15   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(cm_val, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCqI68VcDepH",
    "outputId": "80ed6d6e-e668-4a92-be58-c2b9ee5e3278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      1.00      0.92      2355\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         7\n",
      "          13       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00       240\n",
      "           3       0.00      0.00      0.00        84\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00        12\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.86      2745\n",
      "   macro avg       0.07      0.08      0.07      2745\n",
      "weighted avg       0.74      0.86      0.79      2745\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Evaluation metrics for valdation dataset\n",
    "print(metrics.classification_report(true_val_class, pred_val_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xF2j3konDepe"
   },
   "source": [
    "Generating test data frame results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0xfdWeuDepf"
   },
   "outputs": [],
   "source": [
    "result_path=\"C:/Users/andre/NCSA_Python/SPIN_CDC/WNV_forecasting_template_(4-20-2020).csv\"\n",
    "df_result=pd.read_csv(result_path)\n",
    "df_final=pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_list = np.array(df_final).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UoXW-S-eDepi"
   },
   "outputs": [],
   "source": [
    "values={}\n",
    "for i in range(len(df_final_list)):\n",
    "    values[\"{0}\".format(i+1)]=df_final_list[i]\n",
    "values_df = pd.DataFrame.from_dict(values,'index')\n",
    "\n",
    "rename={}\n",
    "for i in range(0,15):\n",
    "    rename[i]=\"{0}\".format(i+1)\n",
    "\n",
    "counties=[]\n",
    "counties_new=[]\n",
    "counties=df_county.values.tolist()\n",
    "for i in counties:\n",
    "    counties_new.append(counties[counties.index(i)][0])\n",
    "    \n",
    "valu_df_re = values_df.rename(rename,axis='columns')\n",
    "valu_df_re[\"County\"]=counties_new\n",
    "cols=valu_df_re.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "valu_df_re=valu_df_re[cols]\n",
    "\n",
    "valu_df_re.to_csv(\"C:/Users/andre/NCSA_Python/SPIN_CDC/Bin_Values_7_21_2020_JING_under1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ANDY_CLEAN_CDC Challenge_model-val_split_prior.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
